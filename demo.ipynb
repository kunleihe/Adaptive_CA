{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aedda24-3b58-430c-a7a7-8c93f86eb515",
   "metadata": {
    "id": "8aedda24-3b58-430c-a7a7-8c93f86eb515"
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "SzXfYJev_YOV",
   "metadata": {
    "id": "SzXfYJev_YOV"
   },
   "source": [
    "Clone the repo and install stuffs so it works on Google Collab. To run it Google Collab, uncomment everything in the cell below. To run it in your local machine, comment it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eB1EyAzX_mB1",
   "metadata": {
    "id": "eB1EyAzX_mB1"
   },
   "source": [
    "# !git clone https://github.com/longxvu/Adaptive_CA\n",
    "# from google.colab import files\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # To find local version of the library\n",
    "# sys.path.append(os.path.join(\".\", 'Adaptive_CA'))\n",
    "# %cd Adaptive_CA\n",
    "\n",
    "# # Install necessary library\n",
    "# !pip install openai"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef05612-5579-4577-839d-d1e7673cc946",
   "metadata": {
    "id": "2ef05612-5579-4577-839d-d1e7673cc946"
   },
   "source": [
    "from assistant import GPTAssistant\n",
    "from utils import show_json, list_all_assistant, get_api_key, generate_question_configuration\n",
    "from tool_functions import display_quiz_function_json, generate_feedback_function_json\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e0326c77-da2f-4d89-b72f-ee0fb7b5c4d7",
   "metadata": {
    "id": "e0326c77-da2f-4d89-b72f-ee0fb7b5c4d7"
   },
   "source": [
    "## Init client and choosing our previously created assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5e33d0-bd91-4acf-976b-f6502d83e36f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce5e33d0-bd91-4acf-976b-f6502d83e36f",
    "outputId": "3621300e-d80e-4dfe-9070-863cef97078a"
   },
   "source": [
    "# Create client and retrieve all current assistant\n",
    "client = OpenAI(\n",
    "    api_key=get_api_key()\n",
    ")   # Maybe client should be outside assistant class but this will do for now"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41897b2f-b9a2-41c9-adf5-fb1e7bc6da2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41897b2f-b9a2-41c9-adf5-fb1e7bc6da2d",
    "outputId": "a3c90e32-020d-4fb5-b14b-b2fdda684c60"
   },
   "source": [
    "list_all_assistant(client, concise=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703eaadb-2703-4a67-ac81-e032733e42be",
   "metadata": {
    "id": "703eaadb-2703-4a67-ac81-e032733e42be"
   },
   "source": [
    "# # update the function that assistant will use\n",
    "# client.beta.assistants.update(assistant_id=\"asst_ZNz4lbi6z8bpKkE6APKdrpQ8\", tools=[{\"type\": \"function\", \"function\": display_quiz_function_json}, {\"type\": \"function\", \"function\": generate_feedback_function_json}])\n",
    "# client.beta.assistants.update(assistant_id=\"asst_ZNz4lbi6z8bpKkE6APKdrpQ8\", instructions=\"You will be presented with a couple of dialogue between two cartoon characters.\"\n",
    "#                                                                                           \"You need to identify a few science concepts presented in the dialogue to assist the children in learning \"\n",
    "#                                                                                           \"the concepts.\")\n",
    "# client.beta.assistants.update(assistant_id=\"asst_ZNz4lbi6z8bpKkE6APKdrpQ8\", model=\"gpt-3.5-turbo-0125\")\n",
    "# client.beta.assistants.update(assistant_id=\"asst_ZNz4lbi6z8bpKkE6APKdrpQ8\", model=\"gpt-4-turbo\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37eb68da-d125-4457-8e37-03fee1f337bd",
   "metadata": {
    "id": "37eb68da-d125-4457-8e37-03fee1f337bd"
   },
   "source": [
    "assistant = GPTAssistant(client, assistant_id=\"asst_ZNz4lbi6z8bpKkE6APKdrpQ8\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c804e77a-5ea5-4ed2-b872-9ea97a928cdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c804e77a-5ea5-4ed2-b872-9ea97a928cdc",
    "outputId": "6e29acfa-23b2-4698-f4ab-28aa11ca6a62"
   },
   "source": [
    "print(assistant.assistant.id)\n",
    "print(assistant.thread.id)\n",
    "print(assistant.get_all_messages())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a660a6f6-8bb1-4b9b-b7a2-d374ad598969",
   "metadata": {
    "id": "a660a6f6-8bb1-4b9b-b7a2-d374ad598969"
   },
   "source": [
    "## Get dialogue data from xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d2fdd4f-43a6-47ae-b58b-24aee7c75f00",
   "metadata": {
    "id": "3d2fdd4f-43a6-47ae-b58b-24aee7c75f00"
   },
   "source": [
    "dialogue_file_path = \"transcripts/town_picnic_base.xlsx\"\n",
    "df = pd.read_excel(dialogue_file_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa5e2ef7-bc74-4f24-986b-2e41eab31b09",
   "metadata": {
    "id": "aa5e2ef7-bc74-4f24-986b-2e41eab31b09"
   },
   "source": [
    "transcripts = df[df[\"text\"].notnull()][\"text\"].tolist()\n",
    "base_question = df[df[\"text\"].notnull()][\"base_q\"].tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "749dc156-f1f4-4e84-ad0b-a2f88b5859d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "749dc156-f1f4-4e84-ad0b-a2f88b5859d3",
    "outputId": "0674ec99-a668-4d52-a290-5d28798964a0"
   },
   "source": [
    "print(transcripts[0][0:500] + \"...\")\n",
    "print(\"Base question:\", base_question[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4e712d98-434c-4da0-b710-461de59dcf60",
   "metadata": {
    "id": "4e712d98-434c-4da0-b710-461de59dcf60"
   },
   "source": [
    "## Main GPT dialogue loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85d26eb7-f8c3-40aa-b4d4-90e2c3b1730e",
   "metadata": {
    "id": "85d26eb7-f8c3-40aa-b4d4-90e2c3b1730e"
   },
   "source": [
    "# Can set it to run forever but currently restricting to a limited amount of step for testing\n",
    "max_step = 1\n",
    "# num_questions = 3\n",
    "step = 0\n",
    "cur_dialogue_num = 0\n",
    "\n",
    "difficulty = [\"easy\", \"medium\", \"hard\"]\n",
    "difficulty_weights = [2, 5, 10]\n",
    "question_configurations = generate_question_configuration(3, difficulty_weights)\n",
    "current_difficulty = 5\n",
    "max_score_per_question = 10\n",
    "question_configurations"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282e9e34-359e-446e-8b0a-a7c79d1c888c",
   "metadata": {
    "id": "282e9e34-359e-446e-8b0a-a7c79d1c888c"
   },
   "source": [
    "# Debug tool run\n",
    "# assistant.wait_on_run()\n",
    "# tool_calls = assistant.last_run.required_action.submit_tool_outputs.tool_calls\n",
    "# for tool_call in tool_calls:\n",
    "#     print(json.loads(tool_call.function.arguments))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1457da89-d3f4-41b9-a3b8-ea4b437a06df",
   "metadata": {},
   "source": [
    "# Debug step taken using the tool\n",
    "# run_steps = client.beta.threads.runs.steps.list(\n",
    "#     thread_id=assistant.thread.id, run_id=assistant.last_run.id, order=\"asc\"\n",
    "# )\n",
    "\n",
    "# for idx, step in enumerate(run_steps.data):\n",
    "#     print(f\"{idx+1})\")\n",
    "#     step_details = step.step_details\n",
    "#     print(json.dumps(show_json(step_details), indent=4))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e00cfa5-0155-48ae-87be-479be1efc473",
   "metadata": {
    "id": "0e00cfa5-0155-48ae-87be-479be1efc473"
   },
   "source": [
    "# assistant.resolve_run_required_action()\n",
    "# assistant.get_all_messages()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "566cf833-7fef-425f-9f91-a7bcd3e59be8",
   "metadata": {
    "id": "566cf833-7fef-425f-9f91-a7bcd3e59be8"
   },
   "source": [
    "First, the assistant is presented with the dialogue then it is asked to summarize it. Then we ask it to create a quiz of varying difficulties about the science concept presented in the dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f3c7001-c940-45f3-87f7-990b6dc5e535",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f3c7001-c940-45f3-87f7-990b6dc5e535",
    "outputId": "3e577d22-cd0a-4972-cc86-4383bdf2f261"
   },
   "source": [
    "while step < max_step and cur_dialogue_num < len(transcripts):\n",
    "    # Current question difficulty level:\n",
    "    current_difficulty_configurations, max_possible_score = question_configurations[current_difficulty][:-1], question_configurations[current_difficulty][-1]\n",
    "    print(\"=====\")\n",
    "    diff_config = [f\"{num_q} {diff}\" for diff, num_q in zip(difficulty, current_difficulty_configurations)]\n",
    "    diff_config = \",\".join(diff_config)\n",
    "        \n",
    "    print(f\"Difficulty level: {current_difficulty}. Current question configurations: {diff_config}\")\n",
    "    # Two steps: First, summarize the dialogue (for easier testing, can be omitted). Then ask the question about summarized dialogue\n",
    "    assistant.submit_message(f\"Summarize this dialogue: {transcripts[cur_dialogue_num]}.\")\n",
    "    print(assistant.get_last_response())\n",
    "    print(\"----------------------------\")\n",
    "    assistant.submit_message(f\"\"\"\n",
    "    Generate 3 questions ({diff_config}) to ask the child about the science concept presented in the dialogue. Please don't generate feedback for the quiz here.\n",
    "    \"\"\")\n",
    "    \n",
    "    assistant.wait_on_run()\n",
    "    # if assistant.run_requires_action():\n",
    "    f_result = assistant.resolve_run_required_action()\n",
    "    num_questions, student_responses = f_result[\"display_quiz\"]\n",
    "    print(\"----------------------------\")\n",
    "    print(f\"Question by difficulty: {num_questions}\")\n",
    "    # print(assistant.get_last_response())\n",
    "    # Get feedback\n",
    "    assistant.wait_on_run()\n",
    "    assistant.submit_message(f\"Here are the student's answer: {student_responses}, generate a feedback for the student.\")\n",
    "    f_result = assistant.resolve_run_required_action()\n",
    "    scores, concepts = f_result[\"generate_feedback\"]\n",
    "    assistant.wait_on_run()\n",
    "    print(f\"Scores: {scores}\")\n",
    "\n",
    "    # Here we calculate weighted scores based on the difficulty of each question\n",
    "    # print(num_questions)\n",
    "    # num_questions: (2, 0, 1), scores: [15, 0, 7]. (1st question easy: score 10, 2nd question easy: score: 5, 3rd question hard: score 7)\n",
    "    print(\"----------------------------\")\n",
    "    print(\"Scoreboard\")\n",
    "    for idx, num_question in enumerate(num_questions):\n",
    "        if num_question > 0:\n",
    "            for score in scores[idx]:\n",
    "                print(f\"{difficulty[idx]}: {score}\")\n",
    "    print(\"----------------------------\")\n",
    "    \n",
    "    weighted_scores = [sum(score) / (max_score_per_question * num_q) if num_q != 0 else 0 for num_q, score in zip(num_questions, scores)]\n",
    "    weighted_scores = sum([w_score * num_q * difficulty_weights[idx] for idx, (w_score, num_q) in enumerate(zip(weighted_scores, num_questions))])\n",
    "    normalized_score = weighted_scores / max_possible_score  # Normalized score for current difficulty level\n",
    "    print(f\"Weighted/Max: {weighted_scores}/{max_possible_score}, normalized: {normalized_score}\")\n",
    "    score_range, difficulty_delta = [0.2, 0.4, 0.6, 0.8, 1], [-2, -1, 0, 1, 2]\n",
    "    for max_score_range, delta in zip(score_range, difficulty_delta):\n",
    "        if normalized_score <= max_score_range:\n",
    "            current_difficulty += delta\n",
    "            break\n",
    "    current_difficulty = max(0, min(current_difficulty, len(question_configurations)))  # clamp the value to 0 -> max difficulty\n",
    "    print(f\"Next difficulty is set to: {current_difficulty}\")\n",
    "\n",
    "    step += 1\n",
    "    cur_dialogue_num += 1\n",
    "    print(\"==============================================================================\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d2c8b7c4-3980-4e6a-a03f-e6dd252e1e34",
   "metadata": {},
   "source": [
    "# assistant.submit_message(\"Generate a feedback of the answered quiz\")\n",
    "# assistant.resolve_run_required_action()\n",
    "# assistant.wait_on_run()\n",
    "# assistant.get_last_response()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4842ad20-8637-4954-91f2-39aeb10f0775",
   "metadata": {
    "id": "4842ad20-8637-4954-91f2-39aeb10f0775"
   },
   "source": [
    "# for msg in assistant.get_all_messages():\n",
    "#     print(msg)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "550f329b-3d13-4585-b94b-4e6e188850bd",
   "metadata": {},
   "source": [
    "# generate_question_configuration(3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c619e21-6c66-4922-8e1f-29db3c941611",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
